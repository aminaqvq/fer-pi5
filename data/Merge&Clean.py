import os
import math
import pandas as pd
from collections import defaultdict

# ============== é…ç½®åŒºï¼ˆæŒ‰éœ€ä¿®æ”¹ï¼‰ ==============
BASE_DIR = r"F:\fer-pi5\data\csv"  # ä½ çš„ csv ç›®å½•
MERGED_PATH = os.path.join(BASE_DIR, "merged.csv")

TRAIN_OUT      = os.path.join(BASE_DIR, "train.csv")
VAL_OUT        = os.path.join(BASE_DIR, "val.csv")
TEST_OUT       = os.path.join(BASE_DIR, "test.csv")
UNLABELED_OUT  = os.path.join(BASE_DIR, "unlabeled.csv")

LABEL_COL = "emotion"
RNG_SEED  = 42

# é€‰æ‹© unlabeled ç”Ÿæˆæ¨¡å¼ï¼š "ratio" æˆ– "target"
MODE = "ratio"        # "ratio" | "target"

# MODE="ratio" æ—¶ç”Ÿæ•ˆï¼šæ¯ä¸ªç±»åˆ«é¢„ç•™æ¯”ä¾‹
UNLABELED_RATIO = 0.20   # å»ºè®® 0.1 ~ 0.4ï¼›ä¾‹å¦‚ 0.20 çº¦ç•™ 20%

# MODE="target" æ—¶ç”Ÿæ•ˆï¼šå…¨å±€ç›®æ ‡æ— æ ‡ç­¾æ€»æ•°
UNLABELED_TARGET = 50000

# éªŒè¯/æµ‹è¯•é›†çš„æ¯ç±»æœ€å°æ ·æœ¬æ•°ä¿æŠ¤ï¼ˆlabeled éƒ¨åˆ†ï¼‰
MIN_VAL_PER_CLASS  = 1    # è‹¥ä¸éœ€è¦å¯è®¾ 0
MIN_TEST_PER_CLASS = 1    # è‹¥ä¸éœ€è¦å¯è®¾ 0
# ==============================================


def _print_header(msg: str):
    print("\n" + msg)
    print("-" * len(msg))


def _stats_block(name: str, df: pd.DataFrame, label_col: str):
    total = len(df)
    if total == 0:
        print(f"{name:<10}: {total:>6} æ ·æœ¬ | (ç©º)")
        return
    counts = df[label_col].value_counts().sort_index().to_dict()
    print(f"{name:<10}: {total:>6} æ ·æœ¬ | ç±»åˆ«åˆ†å¸ƒ: {counts}")


def _load_or_merge(base_dir: str, merged_path: str, label_col: str) -> pd.DataFrame:
    train_csv = os.path.join(base_dir, "train_old.csv")
    val_csv   = os.path.join(base_dir, "val_old.csv")
    test_csv  = os.path.join(base_dir, "test_old.csv")

    train_df = pd.read_csv(train_csv)
    val_df   = pd.read_csv(val_csv)
    test_df  = pd.read_csv(test_csv)

    assert set(train_df.columns) == set(val_df.columns) == set(test_df.columns), "CSV åˆ—åä¸ä¸€è‡´ï¼"

    merged_df = pd.concat([train_df, val_df, test_df], ignore_index=True)
    print(f"âœ… åˆå¹¶å®Œæˆï¼Œå…± {len(merged_df)} æ¡æ ·æœ¬ã€‚")
    merged_df.to_csv(merged_path, index=False)
    print(f"ğŸ’¾ å·²ä¿å­˜åˆå¹¶æ–‡ä»¶: {merged_path}")

    # ç»Ÿä¸€åˆ—åå°å†™
    merged_df.columns = [c.lower().strip() for c in merged_df.columns]
    if label_col not in merged_df.columns:
        raise ValueError(f"åˆå¹¶åçš„ CSV ç¼ºå°‘åˆ—: {label_col}")
    return merged_df


def _strict_8_1_1_from_labeled_slice(g: pd.DataFrame, t: int):
    """
    ä»åŒä¸€ç±»åˆ« gï¼ˆå·²éšæœºæ‰“ä¹±ï¼‰ä¸­ï¼ŒæŒ‰æ•´ä»½é…é¢ t äº§å‡ºï¼š
      - Train: 8t
      - Val:   1t
      - Test:  1t
    è¿”å› (train_df, val_df, test_df, leftover_df)
    leftover_df æ˜¯ labeled å‰©ä½™çš„ç¢ç‰‡ï¼ˆä¸è¶³10çš„æ ·æœ¬ï¼‰ï¼Œéœ€å¹¶å…¥ unlabeledã€‚
    """
    n_train, n_val, n_test = 8 * t, t, t
    take = n_train + n_val + n_test
    train = g.iloc[:n_train]
    val   = g.iloc[n_train:n_train + n_val]
    test  = g.iloc[n_train + n_val:take]
    leftover = g.iloc[take:]  # labeled å‰©ä½™ç¢ç‰‡
    return train, val, test, leftover


def main():
    merged_df = _load_or_merge(BASE_DIR, MERGED_PATH, LABEL_COL)

    # å…¨å±€æ‰“ä¹±ï¼Œç±»å†…ä¼šå†æ¬¡æ‰“ä¹±
    merged_df = merged_df.sample(frac=1.0, random_state=RNG_SEED).reset_index(drop=True)

    labels = sorted(merged_df[LABEL_COL].unique())
    per_class_counts = merged_df[LABEL_COL].value_counts().reindex(labels).fillna(0).astype(int)
    print("ğŸ§® æ¯ç±»æ ·æœ¬æ•°:", per_class_counts.to_dict())

    train_parts, val_parts, test_parts, unlab_parts = [], [], [], []

    if MODE not in {"ratio", "target"}:
        raise ValueError("MODE å¿…é¡»æ˜¯ 'ratio' æˆ– 'target'ã€‚")

    if MODE == "target":
        total = len(merged_df)
        target = min(UNLABELED_TARGET, total - 30)  # ç•™ä¸€äº›ç»™ labeled
        # æŒ‰ç±»åˆ«å æ¯”åˆ†é… unlabeled é…é¢ï¼ˆæ•´æ•°å››èˆäº”å…¥ï¼‰ï¼Œæœ€åå†ç”¨ä¸€ä¸ªâ€œå·®é¢ä¿®æ­£â€ç¡®ä¿æ€»æ•°å‡†ç¡®
        raw_alloc = {lab: int(round(target * (per_class_counts[lab] / total))) for lab in labels}
        diff = target - sum(raw_alloc.values())
        # å¯¹å·®é¢è¿›è¡Œä¿®æ­£ï¼šæŒ‰å„ç±»æ ·æœ¬æ•°ä»å¤§åˆ°å°é€ä¸ª +1/-1
        if diff != 0:
            order = sorted(labels, key=lambda l: per_class_counts[l], reverse=(diff > 0))
            i = 0
            while diff != 0 and i < len(order):
                lab = order[i % len(order)]
                raw_alloc[lab] += 1 if diff > 0 else -1
                diff += -1 if diff > 0 else 1
                i += 1

    # ======== æŒ‰ç±»åˆ«æ‰§è¡Œï¼šå…ˆç¡®å®š unlabeledï¼Œå†å¯¹å‰©ä½™åšä¸¥æ ¼ 8:1:1 ========
    for lab, g_all in merged_df.groupby(LABEL_COL, sort=True):
        # ç±»å†…æ‰“ä¹±
        g_all = g_all.sample(frac=1.0, random_state=RNG_SEED)

        n_total = len(g_all)

        # 1) è®¡ç®— unlabeled é¢„ç•™
        if MODE == "ratio":
            n_unlab = int(n_total * UNLABELED_RATIO)
        else:  # MODE == "target"
            n_unlab = raw_alloc.get(lab, 0)

        # é™åˆ¶ä¸è¦æŠ½ç©ºï¼ˆè‡³å°‘ç»™ labeled ç•™å‡ºæœ€å°éœ€è¦ï¼‰
        min_needed = max(10, MIN_VAL_PER_CLASS + MIN_TEST_PER_CLASS)  # è‡³å°‘èƒ½å‡‘å‡º 1 ä»½ 8:1:1ï¼Œæˆ–æ»¡è¶³æœ€å° val/test
        if n_total - n_unlab < min_needed:
            n_unlab = max(0, n_total - min_needed)

        # 2) åˆ‡ç‰‡å¾—åˆ° unlabeled é¢„ç•™ & labeled pool
        #   è¿™é‡Œå…ˆæŠŠâ€œé¢„ç•™ unlabeledâ€æ”¾åˆ°æœ«å°¾ï¼Œä¾¿äºåç»­ labeled é…é¢åˆ‡ç‰‡
        g_labeled  = g_all.iloc[:n_total - n_unlab]
        g_unlab_pre= g_all.iloc[n_total - n_unlab:]

        # 3) åœ¨ labeled pool å†…åšä¸¥æ ¼ 8:1:1 â€”â€” éœ€è¦æ•´ä»½é…é¢ t
        n_lab = len(g_labeled)
        t = n_lab // 10  # æ•´ä»½é…é¢æ•°
        # è‹¥å¼€å¯æœ€å° val/test ä¿æŠ¤ï¼Œç¡®ä¿ t è‡³å°‘èƒ½æ»¡è¶³å„è‡ªæœ€å°éœ€æ±‚ï¼š
        t_min_by_val  = math.ceil(MIN_VAL_PER_CLASS) if MIN_VAL_PER_CLASS > 0 else 0
        t_min_by_test = math.ceil(MIN_TEST_PER_CLASS) if MIN_TEST_PER_CLASS > 0 else 0
        t_required = max(t_min_by_val, t_min_by_test)
        t = min(t, t) if t_required == 0 else max(0, min(t, t))  # ä¸ºå¯è¯»ï¼Œä¿æŒ t ä¸å˜
        if t < t_required:
            # labeled pool ä¸è¶³ä»¥æ»¡è¶³æœ€å° val/testï¼Œåˆ™é€€è€Œæ±‚å…¶æ¬¡ï¼šæŠŠå…¨éƒ¨è¿› unlabeledï¼Œé¿å…ç ´å 8:1:1
            unlab_parts.append(g_all)
            continue

        # 4) åˆ†é… 8:1:1ï¼Œå¹¶æŠŠ labeled leftover ä¹Ÿæ”¾è¿› unlabeled
        tr, va, te, leftover_lab = _strict_8_1_1_from_labeled_slice(g_labeled, t)

        # 5) ç»„è£…å„éƒ¨åˆ†
        train_parts.append(tr)
        val_parts.append(va)
        test_parts.append(te)

        # unlabeled = é¢„ç•™ + labeled çš„ leftover ç¢ç‰‡
        if len(leftover_lab) > 0:
            unlab_parts.append(leftover_lab)
        if len(g_unlab_pre) > 0:
            unlab_parts.append(g_unlab_pre)

    # ======== æ‹¼æ¥å¹¶å¯¼å‡º ========
    train_df = pd.concat(train_parts, ignore_index=True) if train_parts else pd.DataFrame(columns=merged_df.columns)
    val_df   = pd.concat(val_parts,   ignore_index=True) if val_parts   else pd.DataFrame(columns=merged_df.columns)
    test_df  = pd.concat(test_parts,  ignore_index=True) if test_parts  else pd.DataFrame(columns=merged_df.columns)
    unlab_df = pd.concat(unlab_parts, ignore_index=True) if unlab_parts else pd.DataFrame(columns=merged_df.columns)

    # å®ˆæ’æ ¡éªŒ
    assert len(train_df) + len(val_df) + len(test_df) + len(unlab_df) == len(merged_df), "æ ·æœ¬æ•°ä¸å®ˆæ’ï¼"

    _print_header("ğŸ“Š åˆ’åˆ†ç»“æœ")
    _stats_block("Train",     train_df, LABEL_COL)
    _stats_block("Val",       val_df,   LABEL_COL)
    _stats_block("Test",      test_df,  LABEL_COL)
    _stats_block("Unlabeled", unlab_df, LABEL_COL)

    # å¯¼å‡º
    train_df.to_csv(TRAIN_OUT, index=False)
    val_df.to_csv(VAL_OUT, index=False)
    test_df.to_csv(TEST_OUT, index=False)
    unlab_df.to_csv(UNLABELED_OUT, index=False)

    _print_header("âœ… å¯¼å‡ºå®Œæˆ")
    print(f"Train     -> {TRAIN_OUT}")
    print(f"Val       -> {VAL_OUT}")
    print(f"Test      -> {TEST_OUT}")
    print(f"Unlabeled -> {UNLABELED_OUT}")


if __name__ == "__main__":
    main()